# FIRST: make sure to have unfolded data, derived / ancestral state is defined
# recommendations: if you have outgroup or ancient population, extract new SNPs, by excluding monomorphic SNPs in ancient population.
# use for instance vcftools count/ freq for this compare counts and keep snps that are monomorphic in ancient population
# usecontruct consensus sequence using ancient pop

vcftools --vcf  freebayes.SNPs.filtered.final.98.recode.vcf --keep ../pop/norway --counts2 --out norway
vcftools --vcf  freebayes.SNPs.filtered.final.98.recode.vcf --keep ../pop/ARD --counts2 --out ARD 

## start R
R
ard_f=read.table("ARD.frq",sep="\t",header=T,fill=T,row.names=NULL)
ard_c=read.table("ARD.frq.count",sep="\t",header=T,fill=T,row.names=NULL)
norway_f=read.table("norway.frq",sep="\t",header=T,fill=T,row.names=NULL)
norway_c=read.table("norway.frq.count",sep="\t",header=T,fill=T,row.names=NULL)
# extract snps which freq = 0 in ancient population
anc=ARD[ARD[,8]==0,5]
res=NOR[ARD[,8]==0,]
out=cbind(res,anc)
out2=na.omit(out)
write.table(out2,"keep",row.names=F,quote=F,sep="\t")
## end R

## use first two columns to extract snps, edit file
awk '{print $1"\t"$2}' keep >keep2

vcftools --vcf  freebayes.SNPs.filtered.final.98.recode.vcf --keep ../pop/norway --positions keep2 --recode --out unique
scp unique.recode.vcf dadi/

# construct consesnus fasta sequence
cat ~/data/symphodus_melops.fasta | vcf-consensus ARD_only.recode.vcf.gz -s ARD15 > ARD.consensus.fasta

#  use script to convert vcf to dadi SFS
#  https://groups.google.com/group/dadi-user/attach/15ae6994986666dc/convert_vcf_to_dadi_input.pl?part=0.1&authuser=0&view=1
#
# requires a vcffile, genomefastafile and a list file decribing the samples, 2 columns

cd ~data/bam_fixrg_dedup/freebayes/dadi
perl convert_vcf_2_dadi.pl ../ARD.consensus.fasta unique.recode.vcf list2



# Start dadi
python
import numpy 
import dadi
import pylab


################
# load  data
print 'Reading data'
dd = dadi.Misc.make_data_dict('list2.data')
data = dadi.Spectrum.from_data_dict(dd, ['Skagerak','Northsea'], [33,24], polarized=False)
# end loading data
################

################
### Calculate descriptive statistics
ns = data.sample_sizes
print 'DADI analysis ================================================'
print 'Raw data: file list2.fs'
print 'samples sizes:', ns
print 
S = data.S()
print "Segregating sites:",S
Fst = data.Fst()
print "FST:",Fst
print "Marginalized Spectrum populations aka combining Skagerak + Northsea"
margdata = data.marginalize([1])
theta_w =  margdata.Watterson_theta()
print "Watterson's theta:", theta_w
# end calculate descriptive statistics
################

##########################
#### pre-otimization steps
# define grid size
pts_l = [30,40,50]

# define bounds 
# bound are IMPORTANT. they contain the solotion. 
upper_bound = [100, 100, 100, 10, 3, 3]
lower_bound = [1e-2, 1e-2, 1e-2, 0, 0, 0]

#parametrs
p0 = [2,0.1,2,1,0.2,0.2]
# Perturb our parameters before optimization.
p0 = dadi.Misc.perturb_params(p0, fold=1, upper_bound=upper_bound,lower_bound=lower_bound)
# end-optimization steps
#############################

# we will use all models provided in dady "Demographics2D.py"
# 1. snm =  Standard neutral model, populations never diverge.
# 2. bottlegrowth = Instantanous size change followed by exponential growth with no population split.
# 3. bottlegrowth_split = Instantanous size change followed by exponential growth then split.
# 4. bottlegrowth_split_mig = Instantanous size change followed by exponential growth then split with migration.
# 5. split_mig = Split into two populations of specifed size, with migration.
# 6. IM =  Isolation-with-migration model with exponential pop growth.
# 7. IM_pre = Isolation-with-migration model with exponential pop growth and a size change prior to split.


# nub: The bottleneck size for both pops
# nue: The recovery size for both pops
# m1: The scaled migration rate
# m2: The scaled migration rate
# T1: The scaled time of the bottleneck.
# T2: The scaled time of the recovery
# T3: The scaled time of the admixture
# n1,n2: Size of fs to generate.
# pts: Number of points to use in grid for evaluation

############################################################ Standard neutral model ###################################################

# define 2D netural model
func = dadi.Demographics2D.snm
func_ex = dadi.Numerics.make_extrap_log_func(func)

##########################
#### optimization
print('Beginning optimization ************************************************')
popt = dadi.Inference.optimize_log(p0, data, func_ex, pts_l, 
                                   lower_bound=lower_bound,
                                   upper_bound=upper_bound,
                                   verbose=len(p0),maxiter=1000)
# The verbose argument controls how often progress of the optimizer should be
# printed. It's useful to keep track of optimization process.
# The verbose argument controls how often progress of the optimizer should be
# printed. It's useful to keep track of optimization process.
print('Finshed optimization **************************************************')
# end optimization 
#############################

##########################
#### print results and make plot
print('Best-fit parameters: {0}'.format(popt))
# Calculate the best-fit model AFS.
model = func_ex(popt, ns, pts_l)
# Likelihood of the data given the model AFS.
ll_model = dadi.Inference.ll_multinom(model, data)
print('Maximum log composite likelihood: {0}'.format(ll_model))
# Plot a comparison of the resulting fs with the data.
import pylab
pylab.figure(1)
dadi.Plotting.plot_2d_comp_multinom(model, data, vmin=1, resid_range=3,pop_ids =('Skagerak','Northsea'))
print('Maximum log composite likelihood: {0}'.format(ll_model))
pylab.savefig('Skagerak_Northsea.2Dsnm.png', dpi=300)
# end print results and make plot
#############################


############################################################ BOTTLEGROWTH ########################################################
# Params are nuB,nuF,TF; 
# nuB: Ratio of bottleneck population size to ancient pop size, 
# nuF: Ratio of contemporary to ancient pop size,
# TF: Time since bottleneck recovery

nuB=5
nuF=5
T=100

params = (nuB,nuF,T)


func = dadi.Demographics2D.bottlegrowth
func_ex = dadi.Numerics.make_extrap_log_func(func)

upper_bound = [10,10,200]
lower_bound = [0.001,0.001,20] 

p0 = dadi.Misc.perturb_params(params, fold=2, lower_bound = lower_bound, upper_bound = upper_bound)

##########################
#### optimization
print('Beginning optimization ************************************************')
popt = dadi.Inference.optimize_log(p0, data, func_ex, pts_l, 
                                   lower_bound=lower_bound,
                                   upper_bound=upper_bound,
                                   verbose=len(p0),maxiter=10000)
# The verbose argument controls how often progress of the optimizer should be
# printed. It's useful to keep track of optimization process.
print('Finshed optimization **************************************************')
# end optimization 
#############################

##########################
#### print results and make plot
print('Best-fit parameters: {0}'.format(popt))
# Calculate the best-fit model AFS.
model = func_ex(popt, ns, pts_l)
# Likelihood of the data given the model AFS.
ll_model = dadi.Inference.ll_multinom(model, data)
print('Maximum log composite likelihood: {0}'.format(ll_model))
# Plot a comparison of the resulting fs with the data.
pylab.figure(1)
dadi.Plotting.plot_2d_comp_multinom(model, data, vmin=1, resid_range=3,pop_ids =('Skagerak','Northsea'))
print('Maximum log composite likelihood: {0}'.format(ll_model))
pylab.savefig('Skagerak_Northsea.2D.bottlegrowth.png', dpi=300)
# end print results and make plot
#############################


############################################################ BOTTLEGROWTH SPLIT #####################################################
# Params are nuB,nuF,TF; 
# nuB: Ratio of bottleneck population size to ancient pop size, 
# nuF: Ratio of contemporary to ancient pop size,
# TF: Time since bottleneck recovery
# Ts = Time in the past at which the two populations split

params = (nuB,nuF,T,Ts)

nuB=7
nuF=10
T=5000
Ts=10

params = (nuB,nuF,T,Ts)


func = dadi.Demographics2D.bottlegrowth_split
func_ex = dadi.Numerics.make_extrap_log_func(func)

upper_bound = [100,100,1000,10]
lower_bound = [10,10,100,1] 

p0 = dadi.Misc.perturb_params(params, fold=1, lower_bound = lower_bound, upper_bound = upper_bound)

##########################
#### optimization
print('Beginning optimization ************************************************')
popt = dadi.Inference.optimize(p0, data, func_ex, pts_l, 
                                   lower_bound=lower_bound,
                                   upper_bound=upper_bound,
                                   verbose=len(p0),maxiter=10)
# The verbose argument controls how often progress of the optimizer should be
# printed. It's useful to keep track of optimization process.
print('Finshed optimization **************************************************')
# end optimization 
#############################
# dadi.Inference.optimize
##########################
#### print results and make plot
print('Best-fit parameters: {0}'.format(popt))
# Calculate the best-fit model AFS.
model = func_ex(popt, ns, pts_l)
# Likelihood of the data given the model AFS.
ll_model = dadi.Inference.ll_multinom(model, data)
print('Maximum log composite likelihood: {0}'.format(ll_model))
# Plot a comparison of the resulting fs with the data.
pylab.figure(1)
dadi.Plotting.plot_2d_comp_multinom(model, data, vmin=1, resid_range=3,pop_ids =('Skagerak','Northsea'))
print('Maximum log composite likelihood: {0}'.format(ll_model))
pylab.savefig('Skagerak_Northsea.2D.bottlegrowth.png', dpi=300)
# end print results and make plot
#############################



############################################################ IM_pre ########################################################
# Isolation-with-migration model with exponential pop growth and a size change prior to split.
# params = (nuPre,TPre,s,nu1,nu2,T,m12,m21)

nuPre=5
TPre = 10
s = 0.01
nu1 = 5
nu2 = 5
T= 1000
m12=0
m21=0


params = (nuPre,TPre,s,nu1,nu2,T,m12,m21)

func = dadi.Demographics2D.IM_pre
func_ex = dadi.Numerics.make_extrap_log_func(func)

upper_bound = [10,20, 0.1,10,10,2000,0,0]
lower_bound = [0.01,0.01, 0.001,0.1,0.1,10,0,0] 

p0 = dadi.Misc.perturb_params(params, fold=1, lower_bound = lower_bound, upper_bound = upper_bound)

##########################
#### optimization
print('Beginning optimization ************************************************')
popt = dadi.Inference.optimize_log(p0, data, func_ex, pts_l, 
                                   lower_bound=lower_bound,
                                   upper_bound=upper_bound,
                                   verbose=len(p0),maxiter=10000)
# The verbose argument controls how often progress of the optimizer should be
# printed. It's useful to keep track of optimization process.
print('Finshed optimization **************************************************')
# end optimization 
#############################

##########################
#### print results and make plot
print('Best-fit parameters: {0}'.format(popt))
# Calculate the best-fit model AFS.
model = func_ex(popt, ns, pts_l)
# Likelihood of the data given the model AFS.
ll_model = dadi.Inference.ll_multinom(model, data)
print('Maximum log composite likelihood: {0}'.format(ll_model))
# Plot a comparison of the resulting fs with the data.
pylab.figure(1)
dadi.Plotting.plot_2d_comp_multinom(model, data, vmin=1, resid_range=3,pop_ids =('Skagerak','Northsea'))
print('Maximum log composite likelihood: {0}'.format(ll_model))
pylab.savefig('Skagerak_Northsea.2D.bottlegrowth.png', dpi=300)
# end print results and make plot
#############################









# Note on units
# mij = migration rate
# Ne = effective population
# mu = mutaiton rate
# K = numer of segregating sites
# L = numer of SNPs
# g = generation time

# For example, I have got θ, nu, mij and T.
# In dadi manual, Nref is calculated with θ/4u. While, in some papers with SNP data, θ/4uL is used to get Nref,
# where L is number of analyzed sites. Which equation is OK? = theta = 4*mu*L*Nref 
# Additionally, if I got Nref=1000, nu=0.5, mij=0.2 , T=2 and generation time g=2 :
# Real time = 2*Nref*T*g = 2*1000*2*2 = 8000 years
# Real population size = nu*Nref = 0.5*1000 = 500 individuals
# Real migration rates = mij/2Nref = 0.2/(2*1000)  = 1e-4     
# which means 0.05 individuals each generation are migrating from population j to population i.
